%% 
%% Copyright 2019-2020 Elsevier Ltd
%% 
%% This file is part of the 'CAS Bundle'.
%% --------------------------------------
%% 
%% It may be distributed under the conditions of the LaTeX Project Public
%% License, either version 1.2 of this license or (at your option) any
%% later version.  The latest version of this license is in
%%    http://www.latex-project.org/lppl.txt
%% and version 1.2 or later is part of all distributions of LaTeX
%% version 1999/12/01 or later.
%% 
%% The list of all files belonging to the 'CAS Bundle' is
%% given in the file `manifest.txt'.
%% 
%% Template article for cas-dc documentclass for 
%% double column output.

%\documentclass[a4paper,fleqn,longmktitle]{cas-dc}
\documentclass[a4paper,fleqn]{cas-dc}

%\usepackage[authoryear,longnamesfirst]{natbib}
%\usepackage[authoryear]{natbib}
\usepackage[numbers]{natbib}

%%%Author definitions
\def\tsc#1{\csdef{#1}{\textsc{\lowercase{#1}}\xspace}}
\tsc{WGM}
\tsc{QE}
\tsc{EP}
\tsc{PMS}
\tsc{BEC}
\tsc{DE}
%%%
% -------------------------------------------------------------------
% Pacotes para inserção de figuras e subfiguras
% \usepackage{subfig,epsfig,tikz,float}		            % Packages de figuras. 
\usepackage{graphicx}
\usepackage{caption}
\usepackage{subcaption}
\graphicspath{ {./figs/} }

% -------------------------------------------------------------------
% \usepackage{amssymb}
% -------------------------------------------------------------------
% Pacotes para inserção de tabelas
\usepackage{booktabs,multicol,multirow,tabularx,array}          % Packages para tabela
\usepackage{natbib}
\usepackage{pifont}
\usepackage{xcolor}
\usepackage{algpseudocode}
\usepackage{algorithm}
% -------------------------------------------------------------------
\PassOptionsToPackage{style=super,nolist}{glossaries}
\PassOptionsToPackage{acronym}{glossaries}
\PassOptionsToPackage{nonumberlist}{glossaries}
\usepackage{glossaries}
\newacronym{cnn}{CNN}{Convolutional Neural Network}
\newacronym{llm}{LLM}{Large Language Model}
\newacronym{cv}{CV}{Computer Vision}
\newacronym{ca}{CA}{Conversational Agents}
\newacronym{nlp}{NLP}{Natural Language Processing}
\newacronym{ml}{ML}{Machine Learning}
\newacronym{nlu}{NLU}{Natural Language Understanding}
\newacronym{ai}{AI}{Artificial Inteligence}
\newacronym{er}{ER}{Named Entity Recognition}
\newacronym{sa}{SA}{Sentiment Analysis}
\newacronym{lsa}{LSA}{Latent Semantic Analysis}
\newacronym{svm}{SVM}{Support Vector Machine}
\newacronym{dt}{TD}{Decision Tree}
\newacronym{rf}{RF}{Random Forest}
\newacronym{knn}{KNN}{K-Nearest Neighbors}
\newacronym{sebi}{SEBI}{Sun Exposure and Behaviour Inventory}
\newacronym{samscore}{SAMScore}{Self-Assessment of Melanoma Risk Score}
\newacronym{ddl}{DDL}{Distributed Deep Learning}
\makeglossaries
% -------------------------------------------------------------------
\usepackage[utf8]{inputenc} % The default since 2018
\DeclareUnicodeCharacter{200B}{{\hskip 0pt}}
% -------------------------------------------------------------------
\begin{document}
\let\WriteBookmarks\relax
\def\floatpagepagefraction{1}
\def\textpagefraction{.001}
\shorttitle{EmoCare}
\shortauthors{CV Radhakrishnan et~al.}

\title [mode = title]{EmoCare}                     

\credit{Conceptualization of this study, Methodology, Software}

\author[1]{Carla Mendes}[type=editor,
		%auid=000,bioid=1,
		linkedin='carla-mendes-5b3586233',
		orcid=0000-0001-7138-7124]
%\cormark[1]
%\fnmark[1]
\ead{carla.c.mendes@ipleiria.pt}

\address[1]{Computer Science and Communications Research Centre, School of Technology and Management, Polytechnic of Leiria, 2411-901 Leiria, Portugal}

\begin{abstract}



\end{abstract}

%\begin{graphicalabstract}
%\includegraphics{figs/grabs.pdf}
%\end{graphicalabstract}
%
%\begin{highlights}
%\item Research highlights item 1
%\item Research highlights item 2
%\item Research highlights item 3
%\end{highlights}

\begin{keywords}

\end{keywords}


\maketitle

\section{Introdution}
\label{introduction}

\section{Related work}
\label{relatedWork}

\section{Background and contextualization}
\label{backgroundContextualization}

This section aims to review existing literature regarding \gls{ca}, \gls{sa} and mood assessement questionnaires.

\subsection{Conversational agents}
\label{conversationalAgents}

Chatbots, also known as \gls{ca}, are computer programs designed to mimic interactions between humans and computers.

\subsubsection{Classification methods}

\gls{ca} can be classified accordingly to multiple dimensions: goal, interaction mode, knowledge domain and response-generator \cite{hussain_survey_2019}.

Regarding the goal, chatbots can be defined as \textbf{task-oriented} and \textbf{non-task oriented} where task-oriented chatbots are specifically created to handle specific tasks and are programmed to engage in concise conversations, typically limited to a specific domain. On the other hand, non-task-oriented chatbots excel at simulating conversations with individuals and engaging in casual chitchat for entertainment purposes, therefore, operating in open domains, allowing for more open-ended and diverse conversations \cite{hussain_survey_2019}.

\gls{ca} can operate in different interaction modes, including text-based or voice/speech-based interactions. In the text-based mode, users communicate with the chatbot through written messages. This mode is commonly used in chat applications, messaging platforms, and web-based chat interfaces. Users type their queries or statements, and the chatbot responds with text-based messages. On the other hand, voice/speech-based chatbots enable users to interact with the chatbot using spoken language. These chatbots utilize speech recognition technology to convert the user's voice input into text, which is then processed and analyzed to generate appropriate responses. Voice-based chatbots are commonly found in voice assistants like Amazon Alexa, Google Assistant, or Apple Siri. They offer a hands-free and convenient way of interacting with the chatbot, allowing users to engage in natural conversations and perform tasks using voice commands. Lastly, the multi-modal approach allows the chatbot to interact using both text and speech \cite{montenegro_survey_2019}.

In the knowledge domain dimension, \gls{ca} are designed to possess knowledge regarding a specific domain or industry. They are built with specialized knowledge and capabilities tailored to serve a particular purpose or provide assistance within a limited scope. These \gls{ca} are trained and programmed to understand and respond to queries related to a specific topic or domain. For example, a domain-specific chatbot could be created to assist with customer support on an e-commerce website, provide medical advice in the healthcare industry, or offer travel recommendations in the tourism sector. Open-domain chatbots are designed to engage in conversations on a wide range of topics without being limited to a specific domain. They aim to simulate human-like conversations and provide chit-chat, entertainment, or general information across various subjects.

Lastly, \gls{ca} are also categorized accordingly to response generation methods which involve using techniques and algorithms to generate appropriate and meaningful responses to user queries or inputs. Response generation methods are split into:
\begin{itemize}
	\item \textbf{Rule-based}: rely on a predefined set of rules and patterns to generate responses. These rules are typically created by human experts and programmed into the chatbot system. The chatbot matches user inputs with specific patterns or keywords and retrieves corresponding responses. Rule-based systems are effective for simple and structured conversations but may struggle with handling complex or unpredictable queries.
	\item \textbf{Template-based}: use pre-built response templates that are filled with relevant information based on user inputs. These templates contain placeholders for dynamic content such as names, dates, or specific details. The chatbot identifies the intent of the user's query and selects an appropriate template to generate a response. Template-based systems are relatively simple to implement but may lack flexibility and creativity in generating unique responses.
	\item \textbf{Retrieval-based}: store a large dataset of predefined responses and use \gls{ml} techniques to select the most appropriate response based on the user's input. Retrieval-based systems can provide contextually relevant responses but may struggle with generating novel or creative responses.
	\item \textbf{Generative-based}: use advanced \gls{nlp} techniques and machine learning models, such as sequence-to-sequence models or transformers, to generate responses from scratch. These models are trained on large datasets and learn the patterns and structures of human language. Generative models are more versatile in handling diverse user inputs. However, they can be more computationally intensive and require significant computational resources for training and inference.
	\item \textbf{Hybrid Approach} - combine multiple methods mentioned above to leverage the strengths of each approach.
\end{itemize}

\subsubsection{General Architecture}

A robust \gls{ca} system will possess several key components, represented in Figure \ref{fig:generalArchitecture}.

\begin{figure}[htbp]
	\centering
	\includegraphics[width=\linewidth]{figs/GeneralArchitecture.png}
	\caption{Conversational agents general architecture.}
	\label{fig:generalArchitecture}
\end{figure}

During the \gls{nlp} phase, the user's request undergoes various techniques, including tokenization, lemmatization, and stemming. These techniques help extract structured data from the request, which is then passed on to the subsequent component, known as the \gls{nlu} module, responsible for analyzing each incoming user request using various strategies, namely, parsing the request to understand the user's intention and the associated details. The dialogue management module focuses on keeping track of the dialogue context and defining the following actions to perform by analyzing the input request that has been
transformed into understandable structured data by the \gls{ca} system. The data sources serve as repositories for information and data utilized by the dialogue manager. These sources can be either internal or external. Internally, chatbots can access data from templates or rules to understand user requests and generate appropriate responses. Moreover, \gls{ca} can also build their databases from scratch or leverage existing databases that align with their domain and functionality. In contrast, external data sources can be accessed through third-party services like Web APIs, which provide the necessary information. The response generator module plays a crucial role in generating an appropriate response from a pool of potential options after executing an action. This component utilizes the approaches mentioned earlier to generate the most suitable response for the given context.

\subsubsection{Tools}

Rasa \cite{rasa} is an open-source dialogue framework for building conversational \gls{ai} applications. It uses \gls{nlp} techniques and dialogue management to enable interactive and context-aware conversations. Rasa consists of two main components: the \gls{nlu} module for processing user inputs and extracting intents and entities, and the Dialogue Management module for handling conversation flow and decision-making. It supports personalized dialogue policies, provides tools for training and evaluation, and integrates with different channels and platforms. Rasa supports both text-based and voice-based interactions, making it versatile for various applications.

Amazon Lex \cite{aws} is a service provided by Amazon Web Services that allows developers to build, test, and deploy \gls{ca} powered by \gls{ai}. It is designed to create interactive chatbots and virtual assistants that can understand natural language inputs and provide appropriate responses. Amazon Lex leverages advanced natural language models and \gls{ml} algorithms to enable accurate understanding and interpretation of user inputs. It supports both text and speech inputs and outputs, making it suitable for various applications. With Amazon Lex, developers can easily integrate \gls{ca} into their applications or platforms, enabling more intuitive and engaging user experiences.

Dialogflow \cite{dialogflow} is a \gls{nlu} platform developed by Google. It provides tools and capabilities for building \gls{ca}, chatbots, and virtual assistants. With Dialogflow, developers can create, manage, and deploy \gls{ca} across multiple platforms and systems. It supports both text and speech inputs and outputs, allowing users to interact with the \gls{ca} through various channels such as messaging platforms, voice assistants, and websites. This platform utilizes advanced \gls{ml} algorithms to understand and interpret user inputs, extracting important information such as intents (the user's intention) and entities (specific pieces of information). It offers a range of pre-built \gls{nlu} components and features, including \gls{er} and \gls{sa}. Additionally, Dialogflow provides a visual interface for designing conversation flows, managing dialogues, and defining responses.

OpenDial \cite{opendial} is an open-source Java-based toolkit used for building and evaluating speech-based \gls{ca}. It provides a framework and set of tools that enable developers to create interactive dialogue systems capable of engaging in natural language conversations. Furthermore, the toolkit offers a range of features and functionalities for building \gls{ca}. It provides modules for \gls{nlu}, dialogue management, and speech synthesis. OpenDial allows developers to define dialogue policies and strategies to guide the system's behaviour and response generation. It also includes components for handling user input, managing context, and generating appropriate spoken responses. Overall, OpenDial emphasizes modularity and extensibility, enabling developers to customize and adapt the toolkit according to their specific requirements. 

Botpress \cite{botpress} is an open-source platform that enables developers to build, deploy, and manage chatbots and virtual assistants. It provides a visual interface for designing conversational flows and supports both text-based and voice-based interactions. Botpress is written in JavaScript and can be deployed on various platforms. One of the key features of Botpress is its visual flow builder, which allows developers to create complex conversational flows using a drag-and-drop interface. This makes it easy to design the dialogue flow of the chatbot and define the interactions between the user and the bot. Botpress also offers built-in \gls{nlu} capabilities, allowing developers to train the chatbot to understand user intents and extract entities from user inputs.

ChatterBot \cite{chatterbot} is an open-source Python library that facilitates the development of chatbots. The primary focus of ChatterBot is to generate responses based on pre-defined conversational patterns. It uses a machine learning algorithm called \gls{lsa} to train a language model on a given corpus of text data and  then generate appropriate responses based on the patterns it has learned. ChatterBot supports the use of multiple languages and provides various pre-trained language models that can be used out of the box. Additionally, it enables developers to customize the chatbot's behaviour by defining rules, selecting appropriate responses, and handling specific cases. One of the notable features of ChatterBot is its ability to learn and improve over time. It employs a technique called "conversational context" to maintain the history of the conversation and generate contextually relevant responses. 

\section{Architecture}
\label{architecture}

\section{Proposed solution and implementation}
\label{proposedSolution}

\section{Conclusion}
\label{conclusion}
% created our own Chat prepared dataset 

\printcredits

%% Loading bibliography style file
%\bibliographystyle{model1-num-names}
%\bibliographystyle{cas-model2-names}
\bibliographystyle{unsrt} % Estilo de Bibliografia
% Loading bibliography database
\bibliography{cas-refs}


%\vskip3pt

\end{document}
