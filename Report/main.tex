%% 
%% Copyright 2019-2020 Elsevier Ltd
%% 
%% This file is part of the 'CAS Bundle'.
%% --------------------------------------
%% 
%% It may be distributed under the conditions of the LaTeX Project Public
%% License, either version 1.2 of this license or (at your option) any
%% later version.  The latest version of this license is in
%%    http://www.latex-project.org/lppl.txt
%% and version 1.2 or later is part of all distributions of LaTeX
%% version 1999/12/01 or later.
%% 
%% The list of all files belonging to the 'CAS Bundle' is
%% given in the file `manifest.txt'.
%% 
%% Template article for cas-dc documentclass for 
%% double column output.

%\documentclass[a4paper,fleqn,longmktitle]{cas-dc}
\documentclass[a4paper,fleqn]{cas-dc}

%\usepackage[authoryear,longnamesfirst]{natbib}
%\usepackage[authoryear]{natbib}
\usepackage[numbers]{natbib}

%%%Author definitions
\def\tsc#1{\csdef{#1}{\textsc{\lowercase{#1}}\xspace}}
\tsc{WGM}
\tsc{QE}
\tsc{EP}
\tsc{PMS}
\tsc{BEC}
\tsc{DE}
%%%
% -------------------------------------------------------------------
% Pacotes para inserção de figuras e subfiguras
% \usepackage{subfig,epsfig,tikz,float}		            % Packages de figuras. 
\usepackage{graphicx}
\usepackage{caption}
\usepackage{subcaption}
\graphicspath{ {./figs/} }

% -------------------------------------------------------------------
% \usepackage{amssymb}
% -------------------------------------------------------------------
% Pacotes para inserção de tabelas
\usepackage{booktabs,multicol,multirow,tabularx,array}          % Packages para tabela
\usepackage{natbib}
\usepackage{pifont}
\usepackage{xcolor}
\usepackage{algpseudocode}
\usepackage{algorithm}
% -------------------------------------------------------------------
\PassOptionsToPackage{style=super,nolist}{glossaries}
\PassOptionsToPackage{acronym}{glossaries}
\PassOptionsToPackage{nonumberlist}{glossaries}
\usepackage{glossaries}
\newacronym{cnn}{CNN}{Convolutional Neural Network}
\newacronym{llm}{LLM}{Large Language Model}
\newacronym{cv}{CV}{Computer Vision}
\newacronym{ca}{CA}{Conversational Agents}
\newacronym{cs}{CS}{Conversational Systems}
\newacronym{sr}{SR}{Speech Recognition}
\newacronym{nlp}{NLP}{Natural Language Processing}
\newacronym{ml}{ML}{Machine Learning}
\newacronym{nlu}{NLU}{Natural Language Understanding}
\newacronym{ai}{AI}{Artificial Inteligence}
\newacronym{er}{ER}{Named Entity Recognition}
\newacronym{sa}{SA}{Sentiment Analysis}
\newacronym{lsa}{LSA}{Latent Semantic Analysis}
\makeglossaries
% -------------------------------------------------------------------
\usepackage[utf8]{inputenc} % The default since 2018
\DeclareUnicodeCharacter{200B}{{\hskip 0pt}}
% -------------------------------------------------------------------
\begin{document}
\let\WriteBookmarks\relax
\def\floatpagepagefraction{1}
\def\textpagefraction{.001}
\shorttitle{EmoCare}
\shortauthors{Carla Mendes et~al.}

\title [mode = title]{EmoCare}                     

\credit{Conceptualization of this study, Methodology, Software}

\author[1]{Carla Mendes}[type=editor,
		%auid=000,bioid=1,
		linkedin='carla-mendes-5b3586233',
		orcid=0000-0001-7138-7124]
%\cormark[1]
%\fnmark[1]
\ead{carla.c.mendes@ipleiria.pt}

\address[1]{Computer Science and Communications Research Centre, School of Technology and Management, Polytechnic of Leiria, 2411-901 Leiria, Portugal}

\begin{abstract}
Lorem ipsum .............


\end{abstract}

%\begin{graphicalabstract}
%\includegraphics{figs/grabs.pdf}
%\end{graphicalabstract}
%
%\begin{highlights}
%\item Research highlights item 1
%\item Research highlights item 2
%\item Research highlights item 3
%\end{highlights}

\begin{keywords}

\end{keywords}


\maketitle

\section{Introdution}
\label{introduction}

\section{Related work}
\label{relatedWork}

\section{Background and contextualization}
\label{backgroundContextualization}

This section aims to review existing literature regarding \gls{ca}, \gls{sa} and mood assessement questionnaires.

\subsection{Conversational agents}
\label{conversationalAgents}

Chatbots, referred to as \gls{ca} or \gls{cs}, are software applications created to imitate human-computer interactions  \cite{montenegro_survey_2019}.

\subsubsection{Classification methods}

Chatbots can be categorized based on various factors, including their goal, interaction mode, knowledge domain, and response-generation method \cite{hussain_survey_2019}.

\gls{cs} operate using different modes of interaction, namely based on text or speech. In the text-based mode, users communicate with the chatbot by typing their queries or statements, commonly through chat applications, messaging platforms, or web-based chat interfaces. The chatbot responds with text-based messages in return. On the other hand, speech-based chatbots enable users to interact with the chatbot using spoken language. These chatbots employ \gls{sr} technology to convert the user's voice input into text, which is then processed and analyzed to generate appropriate responses. Voice-based chatbots are typically found in voice assistants like Amazon Alexa, Google Assistant, or Apple Siri. They offer a convenient and hands-free method of interacting with the chatbot, enabling users to engage in natural conversations and perform tasks using voice commands. Additionally, chatbots can also adopt a multi-modal approach, allowing interaction through both text and speech \cite{montenegro_survey_2019}.

When considering their objective, chatbots are categorized as either task-oriented or non-task-oriented. Task-oriented chatbots are designed with a specific purpose, focusing on handling particular tasks and engaging in brief conversations, typically within a limited domain. Conversely, non-task-oriented chatbots specialize in emulating conversations with individuals and participating in casual chitchat primarily for entertainment. As a result, they operate in open domains, facilitating more diverse and unrestricted conversations \cite{hussain_survey_2019}.


In terms of response generation methods, chatbots are also classified based on the techniques and algorithms used to generate suitable and meaningful responses to user queries or inputs. These methods can be categorized as follows:
\begin{itemize}
	\item \textbf{Rule-based}: rely on a predefined set of rules and patterns to generate responses. Human experts typically create these rules and program them into the chatbot system. The \gls{ca} then matches user inputs with specific patterns or keywords and retrieves corresponding responses. Rule-based systems work well for simple and structured conversations but may struggle with complex or unpredictable queries.
	\item \textbf{Retrieval-based}: use \gls{ml} techniques to select the most appropriate response based on the user's input from a large dataset of predefined responses. Retrieval-based systems may struggle with creative responses, however provide contextually relevant responses.
	\item \textbf{Template-based}:  use pre-built response templates that are filled with relevant information based on user inputs. These templates contain placeholders for dynamic content such as names, dates, or specific details. The chatbot captures the intents of the user's input and selects an appropriate template to generate a response. Template-based systems may lack flexibility and creativity in generating unique responses but are relatively simple to implement.
	\item \textbf{Generative-based}: rely on advanced \gls{nlp} techniques and \gls{ml} models to create responses from scratch, namely sequence-to-sequence models or transformers. These models are trained on large datasets and learn the patterns and structures of human language. Generative models are more versatile in handling diverse user inputs. However, they can be more computationally intensive and require significant computational resources for training and inference.
	\item \textbf{Hybrid Approach} - combine multiple methods mentioned above to leverage the strengths of each approach.
\end{itemize}

Lastly, in the knowledge domain dimension, chatbots possess specialized knowledge and capabilities tailored to serve specific purposes within a limited scope. They possess knowledge and capabilities customized to fulfill specific objectives or offer assistance within a restricted topic. These chatbots undergo training and programming to comprehend and address inquiries regarding a specific domain. For instance, a chatbot tailored to a particular subject can aid in customer support for an e-commerce platform, provide medical advice in the healthcare sector, or offer travel recommendations within the tourism industry. On the other hand, open-domain chatbots engage in conversations spanning a broad spectrum of topics, free from confinement to any specific domain. They aim to emulate human-like interactions, delivering casual conversation, entertainment, or general information across various subjects \cite{mohamad_2021}.

\subsubsection{General Architecture}

A robust \gls{ca} system will possess several key components, represented in Figure.% \ref{fig:generalArchitecture}.

%\begin{figure}[htbp]
%	\centering
%	\includegraphics[width=\linewidth]{figs/GeneralArchitecture.png}
%	\caption{Conversational agents general architecture.}
%	\label{fig:generalArchitecture}
%\end{figure}

During the \gls{nlp} phase, the user's request undergoes various techniques, including tokenization, lemmatization, and stemming. These techniques help extract structured data from the request, which is then passed on to the subsequent component, known as the \gls{nlu} module, responsible for analyzing each incoming user request using various strategies, namely, parsing the request to understand the user's intention and the associated details. The dialogue management module focuses on keeping track of the dialogue context and defining the following actions to perform by analyzing the input request that has been transformed into understandable structured data by the \gls{ca} system. The data sources serve as repositories for information and data utilized by the dialogue manager. These sources can be either internal or external. Internally, chatbots can access data from templates or rules to understand user requests and generate appropriate responses. Moreover, \gls{ca} can also build their databases from scratch or leverage existing databases that align with their domain and functionality. In contrast, external data sources can be accessed through third-party services like Web APIs, which provide the necessary information. The response generator module plays a crucial role in generating an appropriate response from a pool of potential options after executing an action. This component utilizes the approaches mentioned earlier to generate the most suitable response for the given context.

\subsubsection{Tools}

Rasa \cite{rasa} is an open-source dialogue framework for building conversational \gls{ai} applications. It uses \gls{nlp} techniques and dialogue management to enable interactive and context-aware conversations. Rasa consists of two main components: the \gls{nlu} module for processing user inputs and extracting intents and entities, and the Dialogue Management module for handling conversation flow and decision-making. It supports personalized dialogue policies, provides tools for training and evaluation, and integrates with different channels and platforms. Rasa supports both text-based and voice-based interactions, making it versatile for various applications.

Amazon Lex \cite{aws} is a service provided by Amazon Web Services that allows developers to build, test, and deploy \gls{ca} powered by \gls{ai}. It is designed to create interactive chatbots and virtual assistants that can understand natural language inputs and provide appropriate responses. Amazon Lex leverages advanced natural language models and \gls{ml} algorithms to enable accurate understanding and interpretation of user inputs. It supports both text and speech inputs and outputs, making it suitable for various applications. With Amazon Lex, developers can easily integrate \gls{ca} into their applications or platforms, enabling more intuitive and engaging user experiences.

Dialogflow \cite{dialogflow} is a \gls{nlu} platform developed by Google. It provides tools and capabilities for building \gls{ca}, chatbots, and virtual assistants. With Dialogflow, developers can create, manage, and deploy \gls{ca} across multiple platforms and systems. It supports both text and speech inputs and outputs, allowing users to interact with the \gls{ca} through various channels such as messaging platforms, voice assistants, and websites. This platform utilizes advanced \gls{ml} algorithms to understand and interpret user inputs, extracting important information such as intents (the user's intention) and entities (specific pieces of information). It offers a range of pre-built \gls{nlu} components and features, including \gls{er} and \gls{sa}. Additionally, Dialogflow provides a visual interface for designing conversation flows, managing dialogues, and defining responses.

OpenDial \cite{opendial} is an open-source Java-based toolkit used for building and evaluating speech-based \gls{ca}. It provides a framework and set of tools that enable developers to create interactive dialogue systems capable of engaging in natural language conversations. Furthermore, the toolkit offers a range of features and functionalities for building \gls{ca}. It provides modules for \gls{nlu}, dialogue management, and speech synthesis. OpenDial allows developers to define dialogue policies and strategies to guide the system's behaviour and response generation. It also includes components for handling user input, managing context, and generating appropriate spoken responses. Overall, OpenDial emphasizes modularity and extensibility, enabling developers to customize and adapt the toolkit according to their specific requirements. 

Botpress \cite{botpress} is an open-source platform that enables developers to build, deploy, and manage chatbots and virtual assistants. It provides a visual interface for designing conversational flows and supports both text-based and voice-based interactions. Botpress is written in JavaScript and can be deployed on various platforms. One of the key features of Botpress is its visual flow builder, which allows developers to create complex conversational flows using a drag-and-drop interface. This makes it easy to design the dialogue flow of the chatbot and define the interactions between the user and the bot. Botpress also offers built-in \gls{nlu} capabilities, allowing developers to train the chatbot to understand user intents and extract entities from user inputs.

ChatterBot \cite{chatterbot} is an open-source Python library that facilitates the development of chatbots. The primary focus of ChatterBot is to generate responses based on pre-defined conversational patterns. It uses a machine learning algorithm called \gls{lsa} to train a language model on a given corpus of text data and  then generate appropriate responses based on the patterns it has learned. ChatterBot supports the use of multiple languages and provides various pre-trained language models that can be used out of the box. Additionally, it enables developers to customize the chatbot's behaviour by defining rules, selecting appropriate responses, and handling specific cases. One of the notable features of ChatterBot is its ability to learn and improve over time. It employs a technique called "conversational context" to maintain the history of the conversation and generate contextually relevant responses. 

\section{Architecture}
\label{architecture}

\section{Proposed solution and implementation}
\label{proposedSolution}

\section{Conclusion}
\label{conclusion}
\printcredits

%% Loading bibliography style file
%\bibliographystyle{model1-num-names}
%\bibliographystyle{cas-model2-names}
\bibliographystyle{unsrt} % Estilo de Bibliografia
% Loading bibliography database
\bibliography{cas-refs}


%\vskip3pt

\end{document}
